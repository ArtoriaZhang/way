import{_ as e,c as t,o as a,a2 as o}from"./chunks/framework.CCoplHXX.js";const b=JSON.parse('{"title":"Origin From","description":"","frontmatter":{},"headers":[],"relativePath":"docs/database/oracle/Isolation.md","filePath":"docs/database/oracle/Isolation.md"}'),s={name:"docs/database/oracle/Isolation.md"},n=o(`<h1 id="origin-from" tabindex="-1">Origin <a href="https://asktom.oracle.com/Misc/oramag/on-transaction-isolation-levels.html" target="_blank" rel="noreferrer">From</a> <a class="header-anchor" href="#origin-from" aria-label="Permalink to &quot;Origin [From](https://asktom.oracle.com/Misc/oramag/on-transaction-isolation-levels.html)&quot;">​</a></h1><h2 id="isolationi-level" tabindex="-1">Isolationi level <a class="header-anchor" href="#isolationi-level" aria-label="Permalink to &quot;Isolationi level&quot;">​</a></h2><ol><li>Read Uncommited</li><li>Read Committed</li><li>Repeatable Read</li><li>Serializable</li></ol><ul><li><p><strong>Dirty read:</strong> The meaning of this term is as bad as it sounds. You&#39;re permitted to read uncommitted, or dirty , data. You can achieve this effect by just opening an OS file that someone else is writing and reading whatever data happens to be there. Data integrity is compromised, foreign keys are violated, and unique constraints are ignored.</p></li><li><p><strong>Nonrepeatable read:</strong> This simply means that if you read a row at time T1 and try to reread that row at time T2, the row may have changed. It may have disappeared, it may have been updated, and so on.</p></li><li><p><strong>Phantom read:</strong> This means that if you execute a query at time T1 and re-execute it at time T2, additional rows may have been added to the database, which may affect your results. This differs from a nonrepeatable read in that with a phantom read, data you already read hasn&#39;t been changed, but instead, more data satisfies your query criteria than before.</p></li></ul><p>Note that the ANSI/ISO SQL standard defines transaction-level characteristics, not just individual statement-by-statement-level characteristics. I&#39;ll examine transaction-level isolation, not just statement-level isolation.</p><p>The SQL isolation levels are defined based on whether they allow each of the preceding phenomena. It&#39;s interesting to note that the SQL standard doesn&#39;t impose a specific locking scheme or mandate particular behaviors, but rather describes these isolation levels in terms of these phenomena—allowing for many different locking/concurrency mechanisms to exist (see Table 1).</p><table><thead><tr><th>Isolation Level</th><th>Dirty Read</th><th>Nonrepeatable Read</th><th>Phantom Read</th></tr></thead><tbody><tr><td>READ UNCOMMITTED</td><td>Permitted</td><td>Permitted</td><td>Permitted</td></tr><tr><td>READ COMMITTED</td><td>--</td><td>Permitted</td><td>Permitted</td></tr><tr><td>REPEATABLE READ</td><td>--</td><td>--</td><td>Permitted</td></tr><tr><td>SERIALIZABLE</td><td></td><td>--</td><td>--</td></tr></tbody></table><p style="text-align:center;">***Table 1:*** ANSI isolation levels</p><h2 id="read-uncommitted" tabindex="-1">- <em><strong>READ UNCOMMITTED:</strong></em> <a class="header-anchor" href="#read-uncommitted" aria-label="Permalink to &quot;- ***READ UNCOMMITTED:***&quot;">​</a></h2><p>The READ UNCOMMITTED isolation level allows dirty reads. Oracle Database doesn&#39;t use dirty reads, nor does it even allow them. The basic goal of a READ UNCOMMITTED isolation level is to provide a standards-based definition that allows for nonblocking reads. As you&#39;ve seen, Oracle Database provides for nonblocking reads by default. You&#39;d be hard-pressed to make a SELECT query block and wait in the database (as noted earlier, there is the special case of a distributed transaction). Every single query, be it a SELECT , INSERT , UPDATE , MERGE , or DELETE , executes in a read-consistent fashion. It might seem funny to refer to an UPDATE statement as a query, but it is. UPDATE statements have two components: a read component as defined by the WHERE clause, and a write component as defined by the SET clause. UPDATE statements read and write to the database, as do all DML statements. The case of a single row INSERT using the VALUES clause is the only exception to this, because such statements have no read component—just the write component.</p><p>I&#39;ll start with that same basic table and query:</p><p>create table accounts ( account_number number primary key, account_balance number not null ); select sum(account_balance) from accounts; Before the query begins, I have the data shown in <strong>Table 2</strong>.</p><table><thead><tr><th>Row</th><th>Account Number</th><th>Account Balance</th></tr></thead><tbody><tr><td>1</td><td>123</td><td>$500.00</td></tr><tr><td>2</td><td>456</td><td>$240.25</td></tr><tr><td>...</td><td>...</td><td>...</td></tr><tr><td>342,023</td><td>987</td><td>$100.00</td></tr></tbody></table><p style="text-align:center;">Table 2: ACCOUNTS table before modifications</p><p>Now, my SELECT statement starts executing and reads row 1, row 2, and so on. At some point while this query is in the middle of processing, a transaction moves $400 from account 123 to account 987. This transaction does the two updates but does not commit. The ACCOUNTS table now looks as shown in Table 3.</p><p>Row Account Number Account Balance Locked? 1 123 ($500.00) changed to $100.00 X 2 456 $240.25 -- ... ... ... -- 342,023 987 ($100.00) changed to $500.00 X</p><p style="text-align:center;">Table 3: ACCOUNTS table during modifications</p><p>As Table 3 shows, two of those rows are locked. If anyone tried to update them, they&#39;d be blocked. So far, the behavior I&#39;m seeing is more or less consistent across all databases. The difference will be in what happens when the query gets to the locked data.</p><p>When the query I&#39;m executing gets to the block containing the locked row (row 342,023) at the bottom of the table, it will notice that the data in it has changed since execution began. To provide a consistent, or correct, answer, Oracle Database will create a copy of the block containing this row as it existed when the query began . That is, it will read a value of $100, which is the value that existed when the query began. Effectively, Oracle Database takes a detour around the modified data—it reads around it, reconstructing it from the undo (also known as a rollback ) segment. A consistent and correct answer comes back without waiting for the transaction to commit.</p><p>Now, a database that allowed a dirty read would simply return the value it saw in account 987 at the time it read it—in this case, $500. The query would count the transferred $400 twice. Therefore, not only does it return the wrong answer, but also it returns a total that never existed in the table. In a multiuser database, a dirty read can be a dangerous feature. Personally, I&#39;ve never seen the usefulness of it. Say that, rather than transferring, the transaction was actually just depositing $400 in account 987. The dirty read would count the $400 and get the &quot;right&quot; answer, wouldn&#39;t it? Well, suppose the uncommitted transaction was rolled back. I&#39;ve just counted $400 that was never actually in the database.</p><p>The point here is that dirty read is not a feature; rather, it&#39;s a liability. In Oracle Database, it&#39;s just not needed. You get all of the advantages of a dirty read—no blocking—without any of the incorrect results.</p><h2 id="read-committed" tabindex="-1">- <em><strong>READ COMMITTED.</strong></em> <a class="header-anchor" href="#read-committed" aria-label="Permalink to &quot;- ***READ COMMITTED.***&quot;">​</a></h2><p>The READ COMMITTED isolation level states that a transaction may read only data that has been committed in the database. There are no dirty reads (reads of uncommitted data). There may be nonrepeatable reads (that is, rereads of the same row may return a different answer in the same transaction) and phantom reads (that is, newly inserted and committed rows become visible to a query that weren&#39;t visible earlier in the trans-action). READ COMMITTED is perhaps the most commonly used isolation level in database applications everywhere, and it&#39;s the default mode for Oracle Database. It&#39;s rare to see a different isolation level used in Oracle databases.</p><p>However, achieving READ COMMITTED isolation is not as cut-and-dried as it sounds. If you look at Table 1, it looks straightforward. Obviously, given the earlier rules, a query executed in any database using the READ COMMITTED isolation will behave in the same way, right? No, it won&#39;t. If you query multiple rows in a single statement in almost any other database, READ COMMITTED isolation can be as bad as a dirty read, depending on the implementation.</p><p>In Oracle Database, using multi-versioning and read-consistent queries, the answer I get from the ACCOUNTS query is the same in the READ COMMITTED example as it was in the READ UNCOMMITTED example. Oracle Database will reconstruct the modified data as it appeared when the query began, returning the answer that was in the database when the query started.</p><p>Now I&#39;ll take a look at how my previous example might work in READ COMMITTED mode in other databases. You might find the answer surprising. I&#39;ll pick up my example at the point described in Table 3:</p><p>I&#39;m in the middle of the table. I&#39;ve read and summed the first N rows.</p><p>The other transaction has moved $400 from account 123 to account 987.</p><p>The transaction has not yet committed, so rows containing the information for accounts 123 and 987 are locked.</p><p>I know what happens in Oracle Database when it gets to account 987: It will read around the modified data, find out it should be $100, and complete. Table 4 shows how another database, running in some default READ COMMITTED mode, might arrive at the answer.</p><p>Table 4: Timeline in a non-Oracle database using READ COMMITTED isolation</p><table><thead><tr><th>Time</th><th>Query</th><th>Account Transfer Transaction</th></tr></thead><tbody><tr><td>T1</td><td>Reads row 1. Sum = $500.00 so far.</td><td>--</td></tr><tr><td>T2</td><td>Reads row 2. Sum = $740.25 so far.</td><td>--</td></tr><tr><td>T3</td><td>--</td><td>Updates row 1 and puts an exclusive lock on row 1, preventing other</td></tr><tr><td>T4</td><td>Reads row N. Sum = . . .</td><td>--</td></tr><tr><td>T5</td><td>--</td><td>Updates row 342,023 and puts an exclusive lock on this row. Row now has $500.00.</td></tr><tr><td>T6</td><td>Tries to read row 342,023 and discovers that it is locked. This session will block and wait for this block to become available. All processing on this query stops .</td><td>--</td></tr><tr><td>T7</td><td>--</td><td>Commits transaction.</td></tr><tr><td>T8</td><td>Reads row 342,023, sees $500.00, and presents a final answer that includes the $400.00 double-counted.</td><td></td></tr></tbody></table><p>Table 4: Timeline in a non-Oracle database using READ COMMITTED isolation</p><p>The first thing to notice in Table 4 is that this other database, upon reading account 987, will block my query. This session must wait on that row until the transaction holding the exclusive lock commits. This is one reason why many people have a bad habit of committing every statement, instead of processing well-formed transactions consisting of all of the statements needed to take the database from one consistent state to the next. Updates interfere with reads in most other databases . The really bad news in this scenario is that I&#39;m making the end user wait for the wrong answer. I still receive an answer that never existed in the database, as with the dirty read, but this time I made the user wait for the wrong answer. In the next section, I&#39;ll look at what these other databases must do to achieve read-consistent, correct results.</p><p>The lesson here is that various databases executing in the same, apparently safe isolation level can and will return very different answers under the same circumstances. It&#39;s important to understand that, in Oracle Database, nonblocking reads are not had at the expense of correct answers. You can have your cake and eat it too, sometimes.</p><h2 id="repeatable-read" tabindex="-1">REPEATABLE READ. <a class="header-anchor" href="#repeatable-read" aria-label="Permalink to &quot;REPEATABLE READ.&quot;">​</a></h2><p>The goal of REPEATABLE READ is to provide an isolation level that gives consistent, correct answers and prevents lost updates. I&#39;ll show examples of what you must do in Oracle Database to achieve these goals and examine what happens in other systems. If you have REPEATABLE READ isolation, the results from a given query must be consistent with respect to some point in time. Most databases (not Oracle) achieve repeatable reads through the use of row-level, shared read locks. A shared read lock prevents other sessions from modifying data that you&#39;ve read. This, of course, decreases concurrency. Oracle Database opted for the more concurrent, multiversioning model to provide read-consistent answers.</p><p>Using multiversioning in Oracle Database, you get an answer consistent with when the query began execution. In other databases, using shared read locks, you get an answer that&#39;s consistent with when the query completes—that is, when you can get the answer at all (more on this in a moment).</p><p>In a system that employs a shared read lock to provide repeatable reads, you&#39;d observe rows in a table getting locked as the query processed them. So, using the earlier example, as my query reads the ACCOUNTS table, it&#39;d leave shared read locks on each row, as shown in Table 5.</p><table><thead><tr><th>Time</th><th>Query</th><th>Account Transfer Transaction</th></tr></thead><tbody><tr><td>T1</td><td>Reads row 1. Sum = $500.00 so far. Block 1 has a shared read lock on it.</td><td>--</td></tr><tr><td>T2</td><td>Reads row 2. Sum = $740.25 so far. Block 2 has a shared read lock on it.</td><td>--</td></tr><tr><td>T3</td><td>--</td><td>Attempts to update row 1 but is blocked. Transaction is suspended until it can obtain an exclusive lock.</td></tr><tr><td>T4</td><td>Reads row N. Sum = . . .</td><td>--</td></tr><tr><td>T5</td><td>Reads row 342,023, sees $100.00, and presents final answer.</td><td>--</td></tr><tr><td>T6</td><td>Commits transaction.</td><td>--</td></tr><tr><td>T7</td><td>--</td><td>Updates row 1 and puts an exclusive lock on this block. Row now has $100.00.</td></tr><tr><td>T8</td><td>--</td><td>Updates row 342,023 and puts an exclusive lock on this block. Row now has $500.00. Commits transaction.</td></tr></tbody></table><p>Table 5: Timeline 1 in a non-Oracle database using READ REPEATABLE isolation</p><p>Table 5 shows that I now get the correct answer, but at the cost of physically blocking one transaction and executing the two transactions sequentially. This is one of the side effects of shared read locks for consistent answers: Readers of data will block writers of data . This is in addition to the fact that, in these systems, writers of data will block readers of data. Imagine if ATMs worked this way in real life.</p><p>So, you can see how shared read locks can inhibit concurrency, but how they can also cause spurious errors to occur. In Table 6, I start with my original table, but this time with the goal of transferring $50 from account 987 to account 123.</p><table><thead><tr><th>Time</th><th>Query</th><th>Account Transfer Transaction</th></tr></thead><tbody><tr><td>T1</td><td>Reads row 1. Sum = $500.00 so far. Block 1 has a shared read lock on it.</td><td>--</td></tr><tr><td>T2</td><td>Reads row 2. Sum = $740.25 so far. Block 2 has a shared read lock on it.</td><td>--</td></tr><tr><td>T3</td><td>--</td><td>Updates row 342,023 and puts an exclusive lock on block 342,023, preventing other updates and shared read locks. This row now has $50.00.</td></tr><tr><td>T4</td><td>Reads row N. Sum = . . .</td><td>--</td></tr><tr><td>T5</td><td>--</td><td>Attempts to update row 1 but is blocked. Transaction is suspended until it can obtain an exclusive lock.</td></tr><tr><td>T6</td><td>Attempts to read row 342,023 but cannot, as an exclusive lock is already in place.</td><td>--</td></tr></tbody></table><p>Table 6: Timeline 2 in a non-Oracle database using READ REPEATABLE isolation</p><p>I&#39;ve just reached the classic deadlock condition. My query holds resources the update needs, and vice versa. My query has just deadlocked with my update transaction. One of them will be chosen as the victim and will be killed. I just spent a long time and a lot of resources only to fail and get rolled back at the end. This is the second side effect of shared read locks: Readers and writers of data can and frequently will deadlock each other .</p><p>As you&#39;ve seen in Oracle Database, you have statement-level read consistency without reads blocking writes or deadlocks. Oracle Database never uses shared read locks—ever. Oracle has chosen the harder-to-implement but infinitely more concurrent multi-versioning scheme.</p><h3 id="serializable" tabindex="-1">SERIALIZABLE <a class="header-anchor" href="#serializable" aria-label="Permalink to &quot;SERIALIZABLE&quot;">​</a></h3><p>This is generally considered the most restrictive level of transaction isolation, but it provides the highest degree of isolation. A SERIALIZABLE transaction operates in an environment that makes it appear as if there are no other users modifying data in the database. Any row you read is assured to be the same upon a reread, and any query you execute is guaranteed to return the same results for the life of a transaction. For example, if you execute—</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>select * from T;</span></span>
<span class="line"><span>begin dbms_lock.sleep( 60*60*24 ); end;</span></span>
<span class="line"><span>select * from T;</span></span></code></pre></div><p>—the answers returned from T would be the same, even though you just slept for 24 hours (or you might get an ORA-1555, snapshot too old error). The isolation level assures you these two queries will always return the same results. Side effects, or changes, made by other transactions aren&#39;t visible to the query no matter how long it has been running.</p><p>Oracle Database takes an optimistic approach to serialization: it gambles on the fact that the data your transaction wants to update won&#39;t be updated by any other transaction. This is typically the way it happens, and usually the gamble pays off, especially in quick transaction, OLTP-type systems. If no one else updates your data during your transaction, this isolation level, which will generally decrease concurrency in other systems, will provide the same degree of concurrency as it would without SERIALIZABLE transactions. The downside is that you may get the ORA-08177 error if the gamble doesn&#39;t pay off. If you think about it, however, it&#39;s worth the risk. If you&#39;re using SERIALIZABLE transaction, you shouldn&#39;t expect to update the same information as other transactions.</p><p>If you do, you should use the SELECT ... FOR UPDATE as described in Chapter 1 [of Expert Oracle Database Architecture: 9i and 10g Programming Techniques and Solutions ]. This will serialize the access. So, you can effectively use an isolation level of SERIALIZABLE if you:</p>`,53),r=[n];function i(d,l,h,c,u,m){return a(),t("div",null,r)}const w=e(s,[["render",i]]);export{b as __pageData,w as default};
